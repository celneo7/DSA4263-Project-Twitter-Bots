{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"twitter_bots_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37438 entries, 0 to 37437\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   default_profile              37438 non-null  bool   \n",
      " 1   default_profile_image        37438 non-null  bool   \n",
      " 2   description                  37438 non-null  object \n",
      " 3   favourites_count             37438 non-null  int64  \n",
      " 4   followers_count              37438 non-null  int64  \n",
      " 5   friends_count                37438 non-null  int64  \n",
      " 6   geo_enabled                  37438 non-null  bool   \n",
      " 7   lang                         37438 non-null  object \n",
      " 8   verified                     37438 non-null  bool   \n",
      " 9   average_tweets_per_day       37438 non-null  float64\n",
      " 10  account_age_days             37438 non-null  int64  \n",
      " 11  account_type                 37438 non-null  object \n",
      " 12  word_count                   37438 non-null  int64  \n",
      " 13  mean_word_length             37438 non-null  float64\n",
      " 14  hashtag_count                37438 non-null  int64  \n",
      " 15  handle_count                 37438 non-null  int64  \n",
      " 16  url_count                    37438 non-null  int64  \n",
      " 17  description_language         37438 non-null  object \n",
      " 18  description_en               24097 non-null  object \n",
      " 19  description_en_embeddings    37438 non-null  object \n",
      " 20  log_followers_friends_ratio  37438 non-null  float64\n",
      "dtypes: bool(4), float64(3), int64(8), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_profile                    0\n",
      "default_profile_image              0\n",
      "description                        0\n",
      "favourites_count                   0\n",
      "followers_count                    0\n",
      "friends_count                      0\n",
      "geo_enabled                        0\n",
      "lang                               0\n",
      "verified                           0\n",
      "average_tweets_per_day             0\n",
      "account_age_days                   0\n",
      "account_type                       0\n",
      "word_count                         0\n",
      "mean_word_length                   0\n",
      "hashtag_count                      0\n",
      "handle_count                       0\n",
      "url_count                          0\n",
      "description_language               0\n",
      "description_en                 13341\n",
      "description_en_embeddings          0\n",
      "log_followers_friends_ratio        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_per_column = df.isna().sum()\n",
    "print(missing_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human    0.668118\n",
       "bot      0.331882\n",
       "Name: account_type, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['account_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (37438, 578)\n",
      "Account distribution: [25013 12425]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['description_en', 'description'])\n",
    "\n",
    "bool_cols = ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']\n",
    "cat_cols = ['lang', 'description_language']\n",
    "num_cols = [\n",
    "    'favourites_count', 'followers_count', 'friends_count',\n",
    "    'average_tweets_per_day', 'account_age_days', 'word_count',\n",
    "    'mean_word_length', 'hashtag_count', 'handle_count',\n",
    "    'url_count', 'log_followers_friends_ratio'\n",
    "]\n",
    "target_col = 'account_type'\n",
    "\n",
    "df[bool_cols] = df[bool_cols].astype(int) # convert to binary values\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True) # one-hot encoding \n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols]) # scale numerical features\n",
    "\n",
    "def str_to_array(s):\n",
    "    s = s.strip(\"[]\")\n",
    "    return np.array(s.split(), dtype=float)\n",
    "df['description_en_embeddings'] = df['description_en_embeddings'].apply(str_to_array) # convert embeddings into array\n",
    "\n",
    "X_embed = np.vstack(df['description_en_embeddings'].values)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in ['description_en_embeddings', target_col]]\n",
    "X_tabular = df[feature_cols].values # all features excleding embeddings\n",
    "\n",
    "X = np.hstack([X_embed, X_tabular])\n",
    "y = df[target_col].map({'human': 0, 'bot': 1}).values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Account Type distribution:\", np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train (80%) and temp (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# split temp into validation (10%) and test (10%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tabular = X_train[:, 384:]  # all cols after the first 384 embedding columns\n",
    "X_val_tabular   = X_val[:, 384:]\n",
    "X_test_tabular  = X_test[:, 384:]\n",
    "\n",
    "# only use embeddings for model1\n",
    "X_train_embed = X_train[:, :384]\n",
    "X_val_embed = X_val[:, :384]\n",
    "X_test_embed = X_test[:, :384]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model1 using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7094017094017094\n",
      "AUC: 0.7578436043120966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      2501\n",
      "           1       0.75      0.19      0.30      1243\n",
      "\n",
      "    accuracy                           0.71      3744\n",
      "   macro avg       0.73      0.58      0.56      3744\n",
      "weighted avg       0.72      0.71      0.64      3744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model1 using logistic regression\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model1.fit(X_train_embed, y_train)\n",
    "\n",
    "y_val_pred = model1.predict(X_val_embed)\n",
    "y_val_prob = model1.predict_proba(X_val_embed)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_val, y_val_prob))\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.7s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.6s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END C=0.001, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.0s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END C=0.001, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.2s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.8s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.5s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=0.01, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.6s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.1s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.5s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.1s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.6s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.01, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   1.9s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.4s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.9s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.8s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.4s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.5s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.4s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.6s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.7s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   2.8s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.6s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.2s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.3s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   2.1s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   0.9s[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.4s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=0.1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   3.3s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   4.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   4.3s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.8s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.6s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.9s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   5.0s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.1s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.6s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   5.9s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.7s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.8s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=   6.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.5s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.2s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.4s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=1, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   4.3s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   8.8s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.6s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   9.3s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.6s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.8s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   9.7s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   9.5s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=   9.5s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.3s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.1s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.7s\n",
      "[CV] END C=10, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.8s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.2s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.7s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.8s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.5s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.6s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.4s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   8.4s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  12.5s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.6s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.8s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=10, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.3s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=  10.0s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.9s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=  11.2s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=  10.9s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.8s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=  10.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l1, solver=liblinear; total time=  10.7s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.5s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.3s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   6.5s\n",
      "[CV] END C=100, class_weight=None, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.5s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=  11.9s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=  11.8s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=  11.8s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  17.1s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  17.5s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  18.1s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.7s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  19.5s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l1, solver=liblinear; total time=  19.9s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.4s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=lbfgs; total time=   2.3s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   7.4s\n",
      "[CV] END C=100, class_weight=balanced, max_iter=1000, penalty=l2, solver=liblinear; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "60 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.70350306 0.71119122 0.5               nan\n",
      " 0.71211146 0.71063551 0.61575771        nan 0.72126981 0.72148934\n",
      " 0.61575771        nan 0.72214073 0.72183907 0.72618013        nan\n",
      " 0.7348055  0.73472249 0.72665618        nan 0.73516123 0.73532377\n",
      " 0.73671913        nan 0.73708177 0.73666611 0.73712891        nan\n",
      " 0.73768019 0.73693879 0.73674226        nan 0.73635417 0.7367545\n",
      " 0.73648187        nan 0.73675847 0.73645203 0.73649665        nan\n",
      " 0.73663192 0.73591028 0.73629354        nan 0.73644019 0.73517589]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best CV ROC-AUC: 0.7376801915943437\n"
     ]
    }
   ],
   "source": [
    "# tuning parameters for model1\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train_embed, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6733440170940171\n",
      "Validation ROC-AUC: 0.757705928087333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.62      0.72      2501\n",
      "           1       0.51      0.79      0.62      1243\n",
      "\n",
      "    accuracy                           0.67      3744\n",
      "   macro avg       0.68      0.70      0.67      3744\n",
      "weighted avg       0.74      0.67      0.68      3744\n",
      "\n",
      "[[1543  958]\n",
      " [ 265  978]]\n"
     ]
    }
   ],
   "source": [
    "# test on validation set\n",
    "best_model1 = grid.best_estimator_\n",
    "y_val_pred = best_model1.predict(X_val_embed)\n",
    "y_val_prob = best_model1.predict_proba(X_val_embed)[:, 1]\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Validation ROC-AUC:\", roc_auc_score(y_val, y_val_prob))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6495726495726496\n",
      "Test ROC-AUC: 0.734433065463893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.69      2502\n",
      "           1       0.48      0.76      0.59      1242\n",
      "\n",
      "    accuracy                           0.65      3744\n",
      "   macro avg       0.66      0.68      0.64      3744\n",
      "weighted avg       0.72      0.65      0.66      3744\n",
      "\n",
      "[[1494 1008]\n",
      " [ 304  938]]\n"
     ]
    }
   ],
   "source": [
    "# test on test set\n",
    "y_test_pred = best_model1.predict(X_test_embed)\n",
    "y_test_prob = best_model1.predict_proba(X_test_embed)[:, 1]\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_test_prob))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.7497565553239478\n",
      "Validation ROC-AUC: 0.757705928087333\n"
     ]
    }
   ],
   "source": [
    "y_train_prob = best_model1.predict_proba(X_train_embed)[:, 1]\n",
    "print(\"Train ROC-AUC:\", roc_auc_score(y_train, y_train_prob))\n",
    "print(\"Validation ROC-AUC:\", roc_auc_score(y_val, y_val_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC are very close, no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities from model1\n",
    "train_prob = best_model1.predict_proba(X_train_embed)[:, 1]\n",
    "val_prob   = best_model1.predict_proba(X_val_embed)[:, 1]\n",
    "test_prob  = best_model1.predict_proba(X_test_embed)[:, 1]\n",
    "\n",
    "# combine probability with tabular features\n",
    "X_train_model2 = np.hstack([train_prob.reshape(-1, 1), X_train_tabular])\n",
    "X_val_model2   = np.hstack([val_prob.reshape(-1, 1), X_val_tabular])\n",
    "X_test_model2  = np.hstack([test_prob.reshape(-1, 1), X_test_tabular])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2 = logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Validation Accuracy: 0.7769764957264957\n",
      "LR Validation ROC-AUC: 0.8648955542481318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82      2501\n",
      "           1       0.63      0.81      0.71      1243\n",
      "\n",
      "    accuracy                           0.78      3744\n",
      "   macro avg       0.76      0.79      0.76      3744\n",
      "weighted avg       0.80      0.78      0.78      3744\n",
      "\n",
      "[[1901  600]\n",
      " [ 235 1008]]\n"
     ]
    }
   ],
   "source": [
    "# initialise model2 using logistic regression\n",
    "model2_lr = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# train on training set\n",
    "model2_lr.fit(X_train_model2, y_train)\n",
    "\n",
    "# predict on validation\n",
    "y_val_pred = model2_lr.predict(X_val_model2)\n",
    "y_val_prob = model2_lr.predict_proba(X_val_model2)[:, 1]\n",
    "\n",
    "# evaluate\n",
    "print(\"LR Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"LR Validation ROC-AUC:\", roc_auc_score(y_val, y_val_prob))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Test Accuracy: 0.7534722222222222\n",
      "LR Test AUC: 0.8480696923942328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80      2502\n",
      "           1       0.60      0.78      0.68      1242\n",
      "\n",
      "    accuracy                           0.75      3744\n",
      "   macro avg       0.74      0.76      0.74      3744\n",
      "weighted avg       0.78      0.75      0.76      3744\n",
      "\n",
      "[[1847  655]\n",
      " [ 268  974]]\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "y_test_pred = model2_lr.predict(X_test_model2)\n",
    "y_test_prob = model2_lr.predict_proba(X_test_model2)[:, 1]\n",
    "\n",
    "print(\"LR Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"LR Test AUC:\", roc_auc_score(y_test, y_test_prob))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2 = random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Validation Accuracy: 0.8774038461538461\n",
      "RF Validation ROC-AUC: 0.9363287669646543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      2501\n",
      "           1       0.88      0.73      0.80      1243\n",
      "\n",
      "    accuracy                           0.88      3744\n",
      "   macro avg       0.88      0.84      0.86      3744\n",
      "weighted avg       0.88      0.88      0.87      3744\n",
      "\n",
      "[[2374  127]\n",
      " [ 332  911]]\n"
     ]
    }
   ],
   "source": [
    "# initialise model2 using random forest\n",
    "model2_rf = RandomForestClassifier(n_estimators=200, max_depth=None, class_weight='balanced', random_state=42)\n",
    "model2_rf.fit(X_train_model2, y_train)\n",
    "\n",
    "# predict on validation set \n",
    "y_val_pred = model2_rf.predict(X_val_model2)\n",
    "y_val_prob = model2_rf.predict_proba(X_val_model2)[:, 1]\n",
    "\n",
    "print(\"RF Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"RF Validation ROC-AUC:\", roc_auc_score(y_val, y_val_prob))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(confusion_matrix(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Test Accuracy: 0.8664529914529915\n",
      "RF Test ROC-AUC: 0.9290438824463778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      2502\n",
      "           1       0.85      0.73      0.78      1242\n",
      "\n",
      "    accuracy                           0.87      3744\n",
      "   macro avg       0.86      0.83      0.84      3744\n",
      "weighted avg       0.87      0.87      0.86      3744\n",
      "\n",
      "[[2343  159]\n",
      " [ 341  901]]\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "y_test_pred = model2_rf.predict(X_test_model2)\n",
    "y_test_prob = model2_rf.predict_proba(X_test_model2)[:, 1]\n",
    "\n",
    "print(\"RF Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"RF Test ROC-AUC:\", roc_auc_score(y_test, y_test_prob))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2 = decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Validation Accuracy: 0.8261217948717948\n",
      "DT Validation ROC-AUC: 0.8006543159083912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      2501\n",
      "           1       0.74      0.72      0.73      1243\n",
      "\n",
      "    accuracy                           0.83      3744\n",
      "   macro avg       0.80      0.80      0.80      3744\n",
      "weighted avg       0.83      0.83      0.83      3744\n",
      "\n",
      "[[2192  309]\n",
      " [ 342  901]]\n"
     ]
    }
   ],
   "source": [
    "# initialise model2 using decision tree\n",
    "model2_dt = DecisionTreeClassifier(max_depth=None, class_weight='balanced', random_state=42)\n",
    "model2_dt.fit(X_train_model2, y_train)\n",
    "\n",
    "# predict on validation set \n",
    "y_val_pred = model2_dt.predict(X_val_model2)\n",
    "y_val_prob = model2_dt.predict_proba(X_val_model2)[:, 1]\n",
    "\n",
    "print(\"DT Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"DT Validation ROC-AUC:\", roc_auc_score(y_val, y_val_prob))\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Test Accuracy: 0.8215811965811965\n",
      "DT Test ROC-AUC: 0.7951435952687126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      2502\n",
      "           1       0.74      0.72      0.73      1242\n",
      "\n",
      "    accuracy                           0.82      3744\n",
      "   macro avg       0.80      0.80      0.80      3744\n",
      "weighted avg       0.82      0.82      0.82      3744\n",
      "\n",
      "[[2186  316]\n",
      " [ 352  890]]\n"
     ]
    }
   ],
   "source": [
    "# predict on test set \n",
    "y_test_pred = model2_dt.predict(X_test_model2)\n",
    "y_test_prob = model2_dt.predict_proba(X_test_model2)[:, 1]\n",
    "\n",
    "print(\"DT Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"DT Test ROC-AUC:\", roc_auc_score(y_test, y_test_prob))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
