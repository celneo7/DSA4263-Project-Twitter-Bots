{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69dd6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15325fc5",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bf1a96c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error reading file: 'utf-8' codec can't decode byte 0xd3 in position 10: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\kagglehub\\pandas_datasets.py:91\u001b[39m, in \u001b[36mload_pandas_dataset\u001b[39m\u001b[34m(handle, path, pandas_kwargs, sql_query)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     result = \u001b[43mread_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m_build_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_build_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:574\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:663\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xd3 in position 10: invalid continuation byte",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the latest version\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mkagglehub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m  \u001b[49m\u001b[43mKaggleDatasetAdapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPANDAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdavidmartngutirrez/twitter-bots-accounts/versions/2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtwitter_human_bots_dataset.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindex_col\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# ignore fully empty lines}  # or \"cp1252\"\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide any additional arguments like \u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# sql_query or pandas_kwargs. See the \u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# documenation for more information:\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFirst 5 records:\u001b[39m\u001b[33m\"\u001b[39m, df.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\kagglehub\\datasets.py:141\u001b[39m, in \u001b[36mdataset_load\u001b[39m\u001b[34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs, polars_frame_type, polars_kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter.PANDAS:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkagglehub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datasets\u001b[39;00m  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkagglehub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpandas_datasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_pandas_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43msql_query\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter.POLARS:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkagglehub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolars_datasets\u001b[39;00m  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CelesteN\\Documents\\nus resources\\dsa4263\\project\\venv\\Lib\\site-packages\\kagglehub\\pandas_datasets.py:97\u001b[39m, in \u001b[36mload_pandas_dataset\u001b[39m\u001b[34m(handle, path, pandas_kwargs, sql_query)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     96\u001b[39m     read_error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError reading file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(read_error_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mValueError\u001b[39m: Error reading file: 'utf-8' codec can't decode byte 0xd3 in position 10: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"davidmartngutirrez/twitter-bots-accounts/versions/2\",\n",
    "  \"twitter_human_bots_dataset.csv\",\n",
    "  pandas_kwargs={\"index_col\": 0}      # ignore fully empty lines}  # or \"cp1252\"\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ef55aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>description</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>profile_background_image_url</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>average_tweets_per_day</th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-15 21:32:11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Blame @xaiax, Inspired by @MakingInvisible, us...</td>\n",
       "      <td>4</td>\n",
       "      <td>1589</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>787405734442958848</td>\n",
       "      <td>en</td>\n",
       "      <td>unknown</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/7874121826...</td>\n",
       "      <td>best_in_dumbest</td>\n",
       "      <td>11041</td>\n",
       "      <td>False</td>\n",
       "      <td>7.870</td>\n",
       "      <td>1403</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-09 05:01:30</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Photographing the American West since 1980. I ...</td>\n",
       "      <td>536</td>\n",
       "      <td>860</td>\n",
       "      <td>880</td>\n",
       "      <td>False</td>\n",
       "      <td>796216118331310080</td>\n",
       "      <td>en</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/8023296328...</td>\n",
       "      <td>CJRubinPhoto</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "      <td>0.183</td>\n",
       "      <td>1379</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-17 05:34:27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Scruffy looking nerf herder and @twitch broadc...</td>\n",
       "      <td>3307</td>\n",
       "      <td>172</td>\n",
       "      <td>594</td>\n",
       "      <td>True</td>\n",
       "      <td>875949740503859204</td>\n",
       "      <td>en</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1278890453...</td>\n",
       "      <td>SVGEGENT</td>\n",
       "      <td>1001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1159</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-21 13:32:25</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Wife.Godmother.Friend.Feline Fanatic! Assistan...</td>\n",
       "      <td>8433</td>\n",
       "      <td>517</td>\n",
       "      <td>633</td>\n",
       "      <td>True</td>\n",
       "      <td>756119643622735875</td>\n",
       "      <td>en</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1284884924...</td>\n",
       "      <td>TinkerVHELPK5</td>\n",
       "      <td>1324</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1489</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-15 16:32:35</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Loan coach at @mancity &amp; Aspiring DJ</td>\n",
       "      <td>88</td>\n",
       "      <td>753678</td>\n",
       "      <td>116</td>\n",
       "      <td>True</td>\n",
       "      <td>464781334</td>\n",
       "      <td>en</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/9952566258...</td>\n",
       "      <td>JoleonLescott</td>\n",
       "      <td>4202</td>\n",
       "      <td>True</td>\n",
       "      <td>1.339</td>\n",
       "      <td>3138</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at  default_profile  default_profile_image  \\\n",
       "0  2016-10-15 21:32:11            False                  False   \n",
       "1  2016-11-09 05:01:30            False                  False   \n",
       "2  2017-06-17 05:34:27            False                  False   \n",
       "3  2016-07-21 13:32:25             True                  False   \n",
       "4  2012-01-15 16:32:35            False                  False   \n",
       "\n",
       "                                         description  favourites_count  \\\n",
       "0  Blame @xaiax, Inspired by @MakingInvisible, us...                 4   \n",
       "1  Photographing the American West since 1980. I ...               536   \n",
       "2  Scruffy looking nerf herder and @twitch broadc...              3307   \n",
       "3  Wife.Godmother.Friend.Feline Fanatic! Assistan...              8433   \n",
       "4               Loan coach at @mancity & Aspiring DJ                88   \n",
       "\n",
       "   followers_count  friends_count  geo_enabled                  id lang  \\\n",
       "0             1589              4        False  787405734442958848   en   \n",
       "1              860            880        False  796216118331310080   en   \n",
       "2              172            594         True  875949740503859204   en   \n",
       "3              517            633         True  756119643622735875   en   \n",
       "4           753678            116         True           464781334   en   \n",
       "\n",
       "                  location                      profile_background_image_url  \\\n",
       "0                  unknown  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "1           Estados Unidos  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "2          Los Angeles, CA  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "3           Birmingham, AL                                               NaN   \n",
       "4  England, United Kingdom  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
       "\n",
       "                                   profile_image_url      screen_name  \\\n",
       "0  http://pbs.twimg.com/profile_images/7874121826...  best_in_dumbest   \n",
       "1  http://pbs.twimg.com/profile_images/8023296328...     CJRubinPhoto   \n",
       "2  http://pbs.twimg.com/profile_images/1278890453...         SVGEGENT   \n",
       "3  http://pbs.twimg.com/profile_images/1284884924...    TinkerVHELPK5   \n",
       "4  http://pbs.twimg.com/profile_images/9952566258...    JoleonLescott   \n",
       "\n",
       "   statuses_count  verified  average_tweets_per_day  account_age_days  \\\n",
       "0           11041     False                   7.870              1403   \n",
       "1             252     False                   0.183              1379   \n",
       "2            1001     False                   0.864              1159   \n",
       "3            1324     False                   0.889              1489   \n",
       "4            4202      True                   1.339              3138   \n",
       "\n",
       "  account_type  \n",
       "0          bot  \n",
       "1        human  \n",
       "2        human  \n",
       "3        human  \n",
       "4        human  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import dataset\n",
    "data = pd.read_csv('../data/external/twitter_human_bots_dataset.csv', index_col=0)\n",
    "df = data\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c76f62",
   "metadata": {},
   "source": [
    "# Creation of New Features for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code to generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a790d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_features.to_csv('new_features.csv') # can rename and only extract new feature cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf251a",
   "metadata": {},
   "source": [
    "# Generation of Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to generate translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcbb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to obtain embeddings  -- cut from hypothesis nb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def embed_descriptions(description_df):\n",
    "    \n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2', token=os.getenv(\"HF_API_KEY\"))\n",
    "    embeddings_lst = []\n",
    "\n",
    "    for i, row in description_df.iterrows():\n",
    "        if row[\"description_en\"]:\n",
    "            embeddings = model.encode(row[\"description_en\"])\n",
    "        else:\n",
    "            embeddings = np.zeros(384, dtype=float)  # default dim=384\n",
    "        embeddings_lst.append(embeddings)\n",
    "\n",
    "        if not i % 1000:\n",
    "            print(f\"progress: {i}\")\n",
    "\n",
    "    description_df[\"description_en_embeddings\"] = embeddings_lst\n",
    "    \n",
    "    return description_df\n",
    "\n",
    "twitter_translated_embeddings_df = embed_descriptions(twitter_translated_embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_translated_embeddings_df.to_csv('embeddings.csv') # just extract embeddings (copy and paste from csv file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
